{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the say can algorithm from google research\n",
    "The SayCan algorithm tries to map langauage to robot control. SayCan is an algorithm that grounds large language models with robotic affordances for long-horizon planning. Given a set of low-level robotic skills (e.g., \"put the green block in the red bowl\") and a high-level instruction (e.g., \"stack all the blocks\"), it scores what a language model believes will help forward the high-level instruction and scores what a robotic affordance model believes is possible. Given a list of low-level and high-level tasks, the LLM will pick tasks that can enable it move forward towards acheiving its goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# start open AI configuration\n",
    "openai.api_base = \"https://api.naga.ac/v1\"\n",
    "openai.api_key =  \"VN7eDdNzbkQkrmEmIr1Gj1Kci3Ed_g6a_atrW14jq6c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install project requirements\n",
    "\n",
    "# !pip install ftfy regex tqdm fvcore imageio==2.4.1 imageio-ffmpeg==0.4.5\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install -U --no-cache-dir gdown --pre\n",
    "# !pip install pybullet moviepy\n",
    "# !pip install flax==0.5.3\n",
    "# !pip install openai\n",
    "# !pip install easydict\n",
    "# !pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install required libraries\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "import cv2  # Used by ViLD.\n",
    "import clip\n",
    "from easydict import EasyDict\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import checkpoints\n",
    "from flax.metrics import tensorboard\n",
    "import imageio\n",
    "from heapq import nlargest\n",
    "import IPython\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "import openai\n",
    "import optax\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import pybullet\n",
    "import pybullet_data\n",
    "import tensorflow.compat.v1 as tf\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
