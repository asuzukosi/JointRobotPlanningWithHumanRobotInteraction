{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the say can algorithm from google research\n",
    "The SayCan algorithm tries to map langauage to robot control. SayCan is an algorithm that grounds large language models with robotic affordances for long-horizon planning. Given a set of low-level robotic skills (e.g., \"put the green block in the red bowl\") and a high-level instruction (e.g., \"stack all the blocks\"), it scores what a language model believes will help forward the high-level instruction and scores what a robotic affordance model believes is possible. Given a list of low-level and high-level tasks, the LLM will pick tasks that can enable it move forward towards acheiving its goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# start open AI configuration\n",
    "openai.api_base = \"https://api.naga.ac/v1\"\n",
    "openai.api_key =  \"VN7eDdNzbkQkrmEmIr1Gj1Kci3Ed_g6a_atrW14jq6c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install project requirements\n",
    "\n",
    "# !pip install ftfy regex tqdm fvcore imageio==2.4.1 imageio-ffmpeg==0.4.5\n",
    "# !pip install git+https://github.com/openai/CLIP.git\n",
    "# !pip install -U --no-cache-dir gdown --pre\n",
    "# !pip install pybullet moviepy\n",
    "# !pip install flax==0.5.3\n",
    "# !pip install openai\n",
    "# !pip install easydict\n",
    "# !pip install imageio-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Oct  3 2023 00:44:16\n"
     ]
    }
   ],
   "source": [
    "# install required libraries\n",
    "import collections\n",
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "import cv2  # Used by ViLD.\n",
    "import clip\n",
    "from easydict import EasyDict\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import checkpoints\n",
    "from flax.metrics import tensorboard\n",
    "import imageio\n",
    "from heapq import nlargest\n",
    "import IPython\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import numpy as np\n",
    "import openai\n",
    "import optax\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import pybullet\n",
    "import pybullet_data\n",
    "import tensorflow.compat.v1 as tf\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kosisochukwuasuzu/Developer/machine_learning/llm-robotics/venv/lib/python3.11/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Access denied with the following error:\n",
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1Cc_fDSBL6QiDvNT4dpfAEbhbALSVoWcc \n",
      "\n",
      "/Users/kosisochukwuasuzu/Developer/machine_learning/llm-robotics/venv/lib/python3.11/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yOMEm-Zp_DL3nItG9RozPeJAmeOldekX\n",
      "To: /Users/kosisochukwuasuzu/Developer/machine_learning/llm-robotics/src/other_implementations/robotiq_2f_85.zip\n",
      "100%|██████████████████████████████████████| 2.33M/2.33M [00:00<00:00, 4.40MB/s]\n",
      "/Users/kosisochukwuasuzu/Developer/machine_learning/llm-robotics/venv/lib/python3.11/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Access denied with the following error:\n",
      "\n",
      " \tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\t https://drive.google.com/uc?id=1GsqNLhEl9dd4Mc3BM0dX3MibOI1FVWNM \n",
      "\n",
      "unzip:  cannot find or open ur5e.zip, ur5e.zip.zip or ur5e.zip.ZIP.\n",
      "Archive:  robotiq_2f_85.zip\n",
      "   creating: robotiq_2f_85/\n",
      "  inflating: robotiq_2f_85/README.md  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-base.mtl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-base.obj  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-base.stl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-coupler.mtl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-coupler.obj  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-coupler.stl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-driver.mtl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-driver.obj  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-driver.stl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-follower.mtl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-follower.obj  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-follower.stl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-pad.stl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-spring_link.mtl  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-spring_link.obj  \n",
      "  inflating: robotiq_2f_85/robotiq-2f-spring_link.stl  \n",
      "  inflating: robotiq_2f_85/robotiq_2f_85.urdf  \n",
      "   creating: robotiq_2f_85/textures/\n",
      "  inflating: robotiq_2f_85/textures/gripper-2f_BaseColor.jpg  \n",
      "  inflating: robotiq_2f_85/textures/gripper-2f_Metallic.jpg  \n",
      "  inflating: robotiq_2f_85/textures/gripper-2f_Normal.jpg  \n",
      "  inflating: robotiq_2f_85/textures/gripper-2f_Roughness.jpg  \n",
      "unzip:  cannot find or open bowl.zip, bowl.zip.zip or bowl.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "# download urdf asset\n",
    "\n",
    "#Download PyBullet assets.\n",
    "if not os.path.exists('ur5e/ur5e.urdf'):\n",
    "  !gdown --id 1Cc_fDSBL6QiDvNT4dpfAEbhbALSVoWcc\n",
    "  !gdown --id 1yOMEm-Zp_DL3nItG9RozPeJAmeOldekX\n",
    "  !gdown --id 1GsqNLhEl9dd4Mc3BM0dX3MibOI1FVWNM\n",
    "  !unzip ur5e.zip\n",
    "  !unzip robotiq_2f_85.zip\n",
    "  !unzip bowl.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup robot environment using pybullet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown Global constants: pick and place objects, colors, workspace bounds\n",
    "\n",
    "PICK_TARGETS = {\n",
    "  \"blue block\": None,\n",
    "  \"red block\": None,\n",
    "  \"green block\": None,\n",
    "  \"yellow block\": None,\n",
    "}\n",
    "\n",
    "COLORS = {\n",
    "    \"blue\":   (78/255,  121/255, 167/255, 255/255),\n",
    "    \"red\":    (255/255,  87/255,  89/255, 255/255),\n",
    "    \"green\":  (89/255,  169/255,  79/255, 255/255),\n",
    "    \"yellow\": (237/255, 201/255,  72/255, 255/255),\n",
    "}\n",
    "\n",
    "PLACE_TARGETS = {\n",
    "  \"blue block\": None,\n",
    "  \"red block\": None,\n",
    "  \"green block\": None,\n",
    "  \"yellow block\": None,\n",
    "\n",
    "  \"blue bowl\": None,\n",
    "  \"red bowl\": None,\n",
    "  \"green bowl\": None,\n",
    "  \"yellow bowl\": None,\n",
    "\n",
    "  \"top left corner\":     (-0.3 + 0.05, -0.2 - 0.05, 0),\n",
    "  \"top right corner\":    (0.3 - 0.05,  -0.2 - 0.05, 0),\n",
    "  \"middle\":              (0,           -0.5,        0),\n",
    "  \"bottom left corner\":  (-0.3 + 0.05, -0.8 + 0.05, 0),\n",
    "  \"bottom right corner\": (0.3 - 0.05,  -0.8 + 0.05, 0),\n",
    "}\n",
    "\n",
    "PIXEL_SIZE = 0.00267857\n",
    "BOUNDS = np.float32([[-0.3, 0.3], [-0.8, -0.2], [0, 0.15]])  # X Y Z\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the robot we will be using in the SayCan experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robotiq2F85:\n",
    "    def __init__(self) ->  None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main logic of the SayCan implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"To pick the blue block and put it on the red block, I should:\\n\"\n",
    "options = make_options(PICK_TARGETS, PLACE_TARGETS)\n",
    "scores, response = gpt3_scoring(query, options, engine=ENGINE, limit_num_options=5, option_start='\\n', verbose=Tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
